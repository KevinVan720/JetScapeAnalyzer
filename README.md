# JetScapeAnalyzer

This repo contains the analysis code for analyzing JETSCAPE final hadron output files. You need to first generate the final hadron output files to analyze them with this package. The hadron files should be named as:

"Hadrons"+str(pThat_Min[n]).zfill(4)+"_"+str(pThat_Max[n]).zfill(4)+"_ev"+str(10*(m)).zfill(3)+"k_to_"+str(10*(m+1)).zfill(3)+"k.dat"

in Python. The first pair of number indicates the pThat bin range. The second pair of numbers indicate the event range. 

## The important classes are contained in analysis.py:

### Particle 

Particle is the class of hadrons. 

### JetScapeReader

JetScapeReader is the class for parsing final hadron files generated by JETSCAPE. It supports different header styles. Header is the line that starts with "#" indicating a new event in the final hadron file. You can read the header inside the hadron file, or reading it from a separate header file. (Because when doing multiple hadronization in JETSCAPE, we can not use pythia to generate the cross sections. We have to use the standalone header file generated when running sub_to_run.py). 

### AnalysisBase

AnalysisBase is the base class for all subsequent analysis. The only assumptions is the hadron files read in are organized by different pThat bins. 

You can read all the actual analysis derived from AnalysisBase. This analysis framework is written to be as flexible as possible. 

When writting a new analysis, rewrite __init__, analyzeEvent, and possibly outputResult.

One thing to notice is that this analysis framework requires the heppy library in python to analyze jets. You can build a docker container using the AnalysisContainer folder. Then bind the input and output folder to /home/input and /home/output. The GRID and NERSC folder contains scripts that I used to actually submit the analysis jobs on the WSU grid and NERSC. Specifically, you can use the docker image docker:wenkaifan/jetscape_analyzer:latest that I have built on NERSC. 

### For the GRID folder:

submit_jobs.py is for analyzing hadron files directly under the OutputFiles folder. submit_jobs_*.py are for analyzing hadron files generated by sub_to_hadronize.py. You will need to create your own singularity container using the AnalysisContainer folder, and put replace the names in the scripts.

### For the NERSC folder:

I use generate_tasks.py to generate the job list .txt files and the submission scripts. The scripts will utilize task farmer and the shifter container that includes the heppy library. You can use the one I've already built on NERSC. 

There are other people's analysis scripts available inside JETSCAPE. For example, Amit has one written in C++, and James has one written in Python.

